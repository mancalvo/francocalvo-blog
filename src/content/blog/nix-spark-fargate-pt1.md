---
author: Franco Calvo
pubDatetime: 2025-01-29T21:00:12Z
title: Poor man's AWS Glue - Nix + PySpark + Fargate
slug: nix+pyspark+fargate+1
featured: true
draft: false
ogImage: /../../assets/nix-spark-fargate/header.svg
tags:
  - nix
  - spark
  - fargate
description:
  Alternativa a AWS Glue Jobs con la creaci√≥n de jobs en Spark de forma
  serverless mediante el uso de Fargate, con builds y entornos de desarrollo
  reproducibles y declarativos con Nix.
---

![Tech icons](../../assets/nix-spark-fargate/header.svg)

## Introducci√≥n

Un tema recurrente que recientemente hemos enfrentado en Draftea es el manejo de
datos cuando estos son lo suficientemente peque√±os como para procesarse de la
forma m√°s eficiente en motores _single-node_, como [DuckDB](https://duckdb.org/)
o [Polars](https://pola.rs/).

Actualmente, la mayor√≠a de las herramientas que se desarrollan en el ecosistema
de datos son "Spark-centric", donde herramientas de la JVM son _first-class
citizens_, y desde ah√≠ se crean integraciones a otros espacios (si bien esto
parece ir cambiando, como con DataFow o Arrow).

Esto nos lleva a pensar c√≥mo podemos aprovechar las integraciones de Spark sin
necesariamente "casarnos" con un framework que de entrada podr√≠a ser _overkill_
para nuestras necesidades. En otras palabras, la idea es utilizar a fondo la
plataforma de integraciones de Spark, pero utilizando herramientas que nos
permitan modular de forma precisa los recursos que utiliza y que adem√°s nos
puedan servir de "trampol√≠n" para luego migrar a otra herramienta con el menor
_overhead_ posible.

## Declarativo, serverless y escalable

### Apache Iceberg como catalizador

Presentemos un problema particular: Apache Iceberg. Este es un _table format_
surgido en Netflix y luego donado a la Fundaci√≥n Apache, que se define como
sigue:

> [...] the Iceberg table format that is designed to manage a large,
> slow-changing collection of files in a distributed file system or key-value
> store as a table.

Actualmente es uno de los formatos m√°s utilizados y mejor integrados en varias
herramientas, como Snowflake, AWS Athena, AWS Glue Catalog, Dremio, Starrocks,
etc. Ofrece garant√≠as ACID junto con un mont√≥n de otras virtudes que hacen que
sea generalmente una pieza central en data lakehouses modernos, y que cumpla un
rol central en lo denominado _Modern Data Stack_.

Sin embargo, actualmente la integraci√≥n de Iceberg en lenguajes o entornos que
no est√©n en Spark o la JVM a√∫n est√° en etapas tempranas, como por ejemplo,
[PyIceberg](https://github.com/apache/iceberg-python), la implementaci√≥n en
Python, que sigue en la versi√≥n 0.8 al momento de escribir este post, donde
faltan aspectos importantes y √∫tiles como `MERGE` DML commands que s√≠ est√°n
disponible en Spark. Estas funcionalidades podr√≠an ser fundamentales en el
dise√±o de tablas _SCD Type 2_ de forma eficiente.

Son generalmente estos _sharp edges_ que hacen que uno termine decant√°ndose por
Spark, por m√°s que sea matar moscas a ca√±onazos. Pero eso no quita que se pueda
optimizar su uso para reducir costos, y tener un manejo de la infraestructura
que nos permita luego evolucionar nuestra soluci√≥n cuando el ecosistema de
paquetes dentro de los _single-node processors_ mejore.

### Spark, pero a que costo?

Ahora, entendiendo la necesidad de utilizar Spark aun con _datasets_ peque√±os,
tenemos que tener en cuenta la eficiencia con lo que estamos corriendo nuestro
proceso. Por ejemplo, un Glue job requiere al menos dos DPUs (unidades de
computo), cada una con un costo de 0.44 USD/h. Esto puede ser un costo
relativamente alto para procesamiento de datos peque√±os.

Una alternativa interesante ser√≠a correrlo de forma standalone en
**containers**. Adem√°s, algo que tiene de ventaja Glue es su condici√≥n de
_serverless_, lo que reduce en gran medida el mantenimiento y elimina la
administraci√≥n de clusters. Ese mismo beneficio lo podemos lograr al correr
nuestros jobs en contenedores en Fargate, con la flexibilidad de asignar tantos
recursos como sea necesario y sin manejar clusters!

### Spark, Fargate... Nix?

![Iceberg is here too](../../assets/nix-spark-fargate/iceberg.svg)

Como dice el titulo, la propuesta a este problema es "Nix + PySpark + Fargate".
Ya explicamos el porque de PySpark y Fargate, y ahora pasamos a la tercera pata
(y la m√°s esot√©rica), que es la clave para lograr entornos reproducibles y
declarativos: **Nix**.

¬øQu√© es Nix? Podemos decir que es un _package builder/manager_, un lenguaje de
programaci√≥n, y un sistema operativo (NixOS), y que tiene como cualidad el ser
declarativo y totalmente reproducible. En el post nos vamos a centrar
principalmente en las primeras dos cualidades.

El uso de Nix nos va a permitir, desde un √∫nico archivo, configurar y declarar:
una shell de desarrollo con todas las dependencias necesarias, una aplicaci√≥n
ejecutable, y una imagen de Docker. Todo esto sin escribir bash, ni TOML, ni un
Dockerfile (pero si nix üòú).

En resumen, Nix es una herramienta muy √∫til, que en nuestro caso nos va a
permitir desarrollar en un entorno relativamente complejo (dependencias de la
JVM, Python, y m√°s) en un marco de trabajo totalmente reproducible a partir de
un archivo de configuraci√≥n declarativo. Esto nos asegura que lo que estemos
corriendo en local, es exactamente lo que estamos empaquetando en una imagen y
subiendola a AWS.

Para un poco m√°s de informaci√≥n, recomiendo leer un poco de la
[p√°gina oficial](https://nixos.org/explore/), o en comunidades de Reddit.

#### Pero y que de Poetry/uv/pipenv/etc!?!?!?!?

Lo vamos a usar! Nix es agn√≥stico al lenguaje. A partir de herramientas como
`uv2nix` o `poetry2nix`, puede integrarse perfectamente a nuestro flujo de
trabajo, incorporando las ventajas de Nix pero sin perder integraci√≥n con
tooling existente.

En nuestro caso, el desarrollo va a ser en `uv` como base, pero podr√≠a
replicarse en general de la misma forma con alguno de los otros manejadores de
paquete.

Como nota, tengo un repo (en desarollo) que funciona como especie de
_quickstart_ para usar Nix con uv:
[nix-python-demo](https://github.com/francocalvo/nix-python-demo/tree/main)

### Spark? No, DuckDB ü•∑

![enter duckdb](../../assets/nix-spark-fargate/duckdb.svg)

A la gente que se enfoca en
[platform engineering](https://platformengineering.org/blog/what-is-platform-engineering),
todo lo anterior le puede resultar super interesante. Pero que valor les da esto
a equipos de negocio o de data? Hasta ahora venimos describiendo Spark with
extra steps.

Como dijimos al principio, llegamos a Spark por necesidad en cuanto a
integraciones, no por su capacidad de computo, por lo que en el momento que el
ecosistema madure, lo mejor ser√≠a poder migrar r√°pidamente al mismo.

Ac√° es donde todo lo que venimos planteando suma mucho valor. DuckDB, uno de los
motores de procesamiento de datos que funcionan en un solo nodo, tiene
implementada una [Spark API](https://duckdb.org/docs/api/python/spark_api.html).
Con la estructura armada, dentro de un container de Fargate, con un toolchain
completo en Python, e idealmente con un sistema de CICD que integre de forma
autom√°tica los cambios en ECR, la migraci√≥n podr√≠a ser en gran medida, y
dependiendo la complejidad del sistema, un par de cambios de l√≠neas de c√≥digo.
Incluso en el peor de los casos el core de la l√≥gica de negocios,
transformaciones y dem√°s, podr√≠a mantenerse.

### Costos

Una pregunta importante a hacerse cuando nos proponemos esto es, vale la pena?
Cuanto puede ser la diferencia entre correr nuestros jobs en Fargate contra
hacerlo en Glue jobs?

La respuesta es que, en casos donde podamos correr nuestros procesos en un solo
nodo (menos de 10-25GB de datos), la diferencia puede ser buena. Llev√°ndolo a
los n√∫meros, y tomando como referencia la configuraci√≥n m√≠nima de Glue (2 DPUs)
y la
[configuraci√≥n m√≠nima recomendada](https://spark.apache.org/docs/latest/hardware-provisioning.html)
para Spark (8GB RAM 8vCPU), podemos ver los siguientes costos:

- 2 DPU \* 0.44 = 0.88 por hora.
- **8 \* 0.04048 + 8 \* 0.004445 = 0.3594 por hora**

Es decir, si nuestra data no es lo suficientemente grande para necesitar
escalar, podr√≠amos estar pagando casi 2.5 veces m√°s por su uso! Esto, adem√°s, es
mejorable, porque podr√≠amos hacer una optimizaci√≥n de recursos de cada job en
Fargate de forma que incluso la diferencia pueda ser mayor, ya que los DPUs
aumentan de forma discreta y en pasos bastante grandes.

## Conclusi√≥n

Si bien falta una segunda parte de este post donde se pueda desplegar la
implementaci√≥n t√©cnica de la propuesta, la idea es dejar en claro que hay buenas
alternativas a el uso de Spark de forma serverless, de forma tal que podamos
apalancarnos de sus integraciones.

As√≠, nuestra alternativa de ‚ÄòNix + PySpark + Fargate‚Äô se presenta como un ‚Äòpoor
man's AWS Glue‚Äô: mantiene la flexibilidad y escalabilidad, pero con un costo y
complejidad m√°s acotados, y la posibilidad de migrar a motores m√°s ligeros como
DuckDB en cuanto el ecosistema lo permita.
